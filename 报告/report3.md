### **基于开源大型语言模型的程序修复：系统构建与模型能力探索**

**答辩人：**  
**日期：2025年7月14日**

---

#### **一、 项目概述**

**各位老师好！**

我本次报告的题目是“基于开源大型语言模型的程序修复：系统构建与模型能力探索”。

**1. 项目目标：**
本项目旨在将 `ChatRepair` 框架从一个依赖闭源API的工具，**升级为一个支持本地化、开源大模型的、更具扩展性的自动化程序修复系统**。

**2. 核心任务：**
*   **系统改造：** 引入开源模型（Qwen）作为修复引擎，并对核心交互逻辑进行增强。
*   **能力验证：** 在 `Defects4J` 数据集上，验证并评估系统的修复能力。
*   **模型对比：** 对比分析开源模型（Qwen3-4B）与先进闭源模型（GPT-4o-mini）在程序修复任务上的性能差异。

---

#### **二、 核心系统构建与创新**

为了达成目标，我们对原有框架进行了三项关键的**建设性改进**。

**1. 可插拔、双语的修复引擎：**
我们设计并实现了一个**可插拔的模型引擎**。通过简单的命令行参数 (`--engine`)，系统可以无缝切换 `Qwen` 和 `ChatGPT`。为适配Qwen，我们还专门编写了**针对性的中文Prompt**，以更好地激发其代码能力。 在主流程中设立了分发逻辑，实现了对不同模型的统一调用，增强了系统的**灵活性和可扩展性**

---

**2. 具备“记忆”的动态提示工程：**
我们发现模型会反复生成已验证失败的错误补丁。为此，我们实现了一个**具备“记忆”功能的动态Prompt生成器**。
*   在每一次新的修复尝试前，系统会自动收集所有**历史失败补丁**。
*   将这些失败记录作为“黑名单”追加到新的Prompt中，明确指示模型“**不要再次生成这些错误代码**”。
*   同时，强化了对输出格式的要求，强制模型仅返回单行代码，并注意括号、逗号等的匹配，避免了语法错误。
*   这一改进显著提升了修复的探索效率，避免了在无效方案上重复试错。

---

**3. 创新三：健壮的自动化验证环境**

*   **问题背景：** `Defects4J` 作为一个十几年前的框架，其测试集在现代环境中存在大量“脆弱测试”（Brittle Tests），这些测试的失败与代码逻辑无关，而是由环境差异导致。
*   **系统加固：** 我们将解决这些问题视为**提升系统健壮性**的一部分。
    *   通过设置 `_JAVA_OPTIONS` 环境变量，我们强制所有测试在**无头模式 (Headless)** 和 **统一的`en_US`区域设置**下运行。
    *   这从根源上解决了因图形界面或系统语言不同导致的验证失败，确保了**验证结果的可靠性和一致性**。

---

#### **三、 实验结果与核心发现**

在 `Defects4J` 数据集上对 `GPT-4o-mini` 和 `Qwen3-4B` 进行了对比测试，得出几点核心发现：

**1. 发现一：自动化修复框架的价值——应对“大海捞针”式的难题**

*   **数据支撑：** `GPT-4o-mini` 成功修复了测试的所有缺陷，但过程并非一帆风顺。例如，修复 `Chart-12` 这个难题，它耗费了**184次**尝试。
*   **结论：** 这个数据有力地证明了，即使是顶尖模型，面对复杂bug也需要大量的试错。这凸显了我们构建的**自动化、多轮试错、带记忆的修复循环**的巨大价值。没有这样的系统，手动进行上百次尝试是不可想象的。

---

**2. 发现二：开源与闭源模型在代码修复任务上存在显著的能力鸿沟**

测试点 | GPT-4o-mini | Qwen3-4B |
---         | --- | ---
Chart-1     | 6 | 51次失败 |
Chart-10    | 1 | 1 |
Chart-11    | 1 | 1 |
Chart-12    | 184 | 24次失败 |
Chart-13    | 2 | 1（见下） |
Chart-20    | 2 | 1 |
Chart-24    | 1 | 10次失败 |
Chart-8     | 1 | 1 |
Chart-9     | 1 | 1 |
Closure-10  | 2 | 1 |
Closure-104 | 7 | 10次失败 |

---

*   **定量对比：**
    *   **GPT-4o-mini：** 成功修复了 `Chart-1`, `Chart-10`, `Chart-11`, `Chart-12` 等多个缺陷。
    *   **Qwen3-4B：** 仅成功修复了 `Chart-10` 和 `Chart-11`。对于 `Chart-1`，在尝试51次后放弃；对于 `Chart-12`，在尝试24次后也宣告失败。

---

*   **定性分析——Qwen的“固执”问题：**
    *   发现 `Qwen3-4B` 存在一个核心问题：**它很难遵循“不要再次生成错误代码”的负向指令**。
    *   **日志证据：** 正如日志所示，在修复 `Chart-12` 时，尽管Prompt在第二轮后明确加入了失败历史 `this.dataset = dataset;`，Qwen在后续的**第3、4、5乃至第15次**尝试中，依然**固执地、反复地**生成完全相同的错误代码。即便将 `temperature` 调高至1.1，也无法打破这种循环。
    *   **深层原因：** 这表明，当前4B量级的开源模型在**遵循复杂指令、尤其是从历史错误中学习的能力**上，与顶尖闭源模型存在本质差距。

    以及，Qwen 也有不严谨的地方。在 Chart-13 样例上它一次就生成了接近正解`new Range(0.0, Math.max(0.0, constraint.getWidth() - w[2])),`的结果，但是遗漏了后面的逗号，导致无法通过测试。

---

**3. 发现三：本地化部署的现实挑战——成本与效率**

*   **效率与成本对比：**
    *   **GPT-4o-mini API：** 调用速度极快，几乎瞬时返回，单次调用成本仅约 **$0.0001**。
    *   **本地Qwen3-4B：** 需要消耗 **18.5GB** 的显存，输出2k token左右的思维链（无法通过prompt避免），单次推理耗时 **1-2分钟**。
*   **结论：** 尽管开源小模型提供了自主可控的优势，但在当前阶段，其高昂的硬件和时间成本，使其在实际的个人小规模应用中的综合性价比远低于高效的闭源API。

---

#### **四、 总结与展望**

**1. 项目总结：**
*   成功将 `ChatRepair` **升级为一个健壮、可扩展、支持多模型的自动化程序修复系统**。
*   核心贡献在于**创新的“带记忆”动态提示策略**和**对底层验证环境的深度加固**。
*   通过实证对比，**量化并深度分析**了当前小型开源模型与顶尖闭源模型在程序修复任务上的能力差距，特别指出了其在**遵循负向指令上的核心短板**。

**2. 未来展望：**
*   **工程层面：** 可以继续优化Prompt策略，或探索更高效的补丁筛选逻辑。
*   **研究层面：** 本系统平台为未来评测更强大的开源模型（如70B以上量级）提供了坚实的基础，有助于持续追踪开源社区在程序修复领域的发展。

**我的报告到此结束，谢谢各位老师！**